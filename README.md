# Simple QA Agent for Machine Learning Documents

This repository provides a simple and extendable Question-Answering (QA) agent built with [LangChain](https://www.langchain.com/) that leverages a local knowledge base of documents (PDF) for answering natural language queries. It uses the `deepseek-chat-v3` LLM via OpenRouter, HuggingFace embeddings, and FAISS vector store.

---

## Features

- üìÑ Load and parse PDF documents using `PyMuPDF`
- üß† Create semantic embeddings using HuggingFace APIs
- üóÉÔ∏è Store document chunks in a FAISS vector index
- ü§ñ Answer user questions using a Retrieval-Augmented Generation (RAG) pipeline
- üîê API access via OpenRouter for language model calls

---

## Requirements

- Python 3.10+
- OpenRouter API key
- HuggingFace embedding endpoint
- LangChain ecosystem packages

---

## Installation

```bash
pip install langchain langchain-openai langchain-community langchain-text-splitters             langchain-huggingface faiss-cpu pymupdf
```

---

## Environment Setup

Before running the notebook, set your API keys:

```python
import os
from getpass import getpass

os.environ['OPENAI_API_KEY'] = getpass('Your OpenRouter key: ')
```

You may also need to set HuggingFace tokens for embedding access.

---

## How It Works

1. **Document Loading**: PDF files are loaded using `PyMuPDFLoader`
2. **Text Splitting**: Documents are split into manageable chunks using `RecursiveCharacterTextSplitter`
3. **Embedding**: Chunks are embedded using `HuggingFaceEndpointEmbeddings`
4. **Indexing**: Embeddings are stored in a FAISS vector store
5. **Query Handling**: User input is used to retrieve relevant chunks and generate a response using `ChatOpenAI`

---

## Usage

Run the Jupyter notebook and follow the steps:

- Set your API keys
- Load PDF documents
- Build the vector store
- Ask questions using the LLM-based agent

---

## Example

```
Question: "What is the difference between supervised and unsupervised learning?"
Answer: [generated by the model using retrieved document context]
```

---

## Limitations

- Works only with English-language PDF documents
- LLM responses depend on document quality and chunking
- FAISS index is stored in memory (no persistence)

---

## License

MIT License or as specified by the author.

---

*Generated on: 2025-08-05*
