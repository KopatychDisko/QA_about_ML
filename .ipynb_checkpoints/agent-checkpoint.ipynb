{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc2646b-6d99-45dc-9817-9cd4ada9b22d",
   "metadata": {},
   "source": [
    "# Simple QA agent for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "332f452d-7992-4743-9f96-fcf4f8c1d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings\n",
    "\n",
    "from getpass import getpass\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5837f17-14ec-4778-ba5a-c8f371a1d13a",
   "metadata": {},
   "source": [
    "## Set evnviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aab77a37-9998-4e7d-bad0-2ac390f7209e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your openrouter key:  ········\n"
     ]
    }
   ],
   "source": [
    "os.environ['OPENAI_API_KEY'] = getpass('Your openrouter key: ')\n",
    "base_url = 'https://openrouter.ai/api/v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279743a4-e956-4be1-b5ce-667016526ca2",
   "metadata": {},
   "source": [
    "## Create model with retvier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fb102c9-803e-4ef1-a126-004d53cf9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model='deepseek/deepseek-chat-v3-0324:free',\n",
    "    base_url=base_url,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e122ac0-bbae-4b9d-b534-04069ad94dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "hug_api:  ········\n"
     ]
    }
   ],
   "source": [
    "model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
    "\n",
    "hf_endpoint_embeddings = HuggingFaceEndpointEmbeddings(\n",
    "    model=model_name,\n",
    "    task=\"feature-extraction\",\n",
    "    huggingfacehub_api_token=getpass('hug_api: ')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a96f2fc1-021a-450b-a019-443b83bce611",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFLoader('deeplearningbook-ml.pdf')\n",
    "doc = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(doc)\n",
    "\n",
    "vectorsotre = FAISS.from_documents(documents=chunks, embedding=hf_endpoint_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91f791f6-879d-4840-8fb4-d98f15bbae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "retvier = vectorsotre.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44e3e546-af23-4133-8a8b-84e6cd2c2d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', \"\"\"You are an assistant for question-answering tasks about ML. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer or dont have context - not answer, just say that you don't know.\n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\"\"\"), \n",
    "        ('human', '{question}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {'context': retvier, 'question': RunnablePassthrough()} |\n",
    "    prompt | \n",
    "    llm | \n",
    "    StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5892e35-ee2d-47b1-b397-5ab4b5ed58ad",
   "metadata": {},
   "source": [
    "## QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11d22c4-a562-4933-b086-ff7554176372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your question:  Linear reggresion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, here's what I can tell you about linear regression:\n",
      "\n",
      "Linear regression is a parametric model that learns a function to predict the value of a scalar output y ∈ ℝ. The model's prediction ŷ is a linear function of the input, defined as:\n",
      "\n",
      "ŷ = wᵀx\n",
      "\n",
      "Where:\n",
      "- w ∈ ℝⁿ is a vector of parameters (weights)\n",
      "- x is the input feature vector\n",
      "- Each weight wᵢ determines how much feature xᵢ affects the prediction\n",
      "\n",
      "Key points from the context:\n",
      "1. If a feature xᵢ has a positive weight wᵢ, increasing that feature's value increases the prediction ŷ\n",
      "2. The model learns to set weights such that the line comes as close as possible to passing through all training points\n",
      "3. The weights are typically found by minimizing the mean squared error on the training set\n",
      "\n",
      "The context also mentions that linear regression is an example of parametric models, which learn a fixed set of parameters from the data.\n",
      "\n",
      "Would you like me to elaborate on any specific aspect of linear regression based on this context?\n",
      "========================================\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your question:  I like football\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have any information about football in the provided context. The documents are about machine learning topics like gradient descent, parametric models, and statistical computations.\n",
      "========================================\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your question:  gradient descent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient descent is an optimization algorithm commonly used in machine learning to minimize a cost function by iteratively moving in the direction of the steepest descent, as defined by the negative of the gradient. \n",
      "\n",
      "Key points from the context:\n",
      "1. **Objective**: It minimizes a cost function \\( J(\\theta) \\), which often decomposes into a sum of per-example losses (e.g., negative log-likelihood).\n",
      "2. **Computational Challenge**: For large datasets, computing the gradient over all training examples (batch gradient descent) is expensive (\\( O(m) \\), where \\( m \\) is the dataset size).\n",
      "3. **Stochastic Gradient Descent (SGD)**: To address this, SGD estimates the gradient using a small **minibatch** of examples (size \\( m' \\), typically 1 to a few hundred). The gradient estimate is:\n",
      "   \\[\n",
      "   g = \\frac{1}{m'} \\nabla_\\theta \\sum_{i=1}^{m'} L(x^{(i)}, y^{(i)}, \\theta),\n",
      "   \\]\n",
      "   and the parameters \\( \\theta \\) are updated as:\n",
      "   \\[\n",
      "   \\theta \\leftarrow \\theta - \\epsilon g,\n",
      "   \\]\n",
      "   where \\( \\epsilon \\) is the learning rate.\n",
      "4. **Efficiency**: SGD allows training on very large datasets by using small, fixed-size minibatches, even when the full dataset is massive.\n",
      "\n",
      "Gradient descent (and its variants like SGD) is foundational for training many machine learning models, especially when exact optimization is computationally infeasible.\n",
      "========================================\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your question:  Do you like cats?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know. The provided context doesn't contain any information about personal preferences regarding cats. It only mentions cats in the context of the \"manifold hypothesis\" in machine learning, discussing how images of cat faces might exist on a different manifold than images of human faces. \n",
      "\n",
      "Would you like me to explain any of the machine learning concepts from the context?\n",
      "========================================\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    print('=' * 40)\n",
    "    print(chain.invoke(input('Your question: ')))\n",
    "    print('=' * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
